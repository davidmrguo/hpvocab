{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import and download packages\n",
                "import pandas as pd\n",
                "import glob\n",
                "import nltk\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "import codecs\n",
                "import json\n",
                "nltk.download('punkt')\n",
                "nltk.download('wordnet')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read CSV into DataFrame\n",
                "df = pd.read_csv('./word_list/grad_total.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.drop_duplicates(subset='word')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean up DataFrame\n",
                "df['in_text'] = 0\n",
                "df['word'] = df['word'].str.lower()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read text files\n",
                "hp_files = glob.glob(\"hp_text/*[1-7].txt\")\n",
                "\n",
                "# Load BrE to AmE dictionary\n",
                "b2a_dict = json.load(open('b2a.json'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "word_list = []\n",
                "for file in hp_files:\n",
                "    with codecs.open(file, 'r', encoding='utf-8',\n",
                "                 errors='ignore') as file_object:\n",
                "        content = file_object.read()\n",
                "        words_in_content = nltk.word_tokenize(content)\n",
                "        for word in words_in_content:\n",
                "            ame_word = b2a_dict.get(word)\n",
                "            lemmatizer = WordNetLemmatizer()\n",
                "            if ame_word:                \n",
                "                word_list.append(lemmatizer.lemmatize(ame_word).lower())\n",
                "            else:\n",
                "                word_list.append(lemmatizer.lemmatize(word).lower())\n",
                "deduped_word_list = list(set(word_list))\n",
                "print(deduped_word_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i_max = df.shape[0]\n",
                "i = 0\n",
                "j = 0\n",
                "\n",
                "while i < i_max:\n",
                "    lemmatizer = WordNetLemmatizer()\n",
                "    loc_word = df['word'].loc[i]\n",
                "    lem_word = lemmatizer.lemmatize(loc_word).lower()\n",
                "    ame_word = b2a_dict.get(lem_word)\n",
                "    if lem_word in deduped_word_list:\n",
                "        df.at[i, 'in_text'] = 1\n",
                "        j += 1\n",
                "    elif ame_word in deduped_word_list:\n",
                "        df.at[i, 'in_text'] = 1\n",
                "        j += 1\n",
                "    i += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output = str(round(j / i_max * 100, 2)) + \"%\"\n",
                "print(output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "c63ef0e16bd3068cbaba0bd7cebd4f043c481c6312de4cb279d9ee86ddd6d348"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit ('venv': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
